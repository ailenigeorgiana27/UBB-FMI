{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Procesarea textelor cu ajutorul LLMs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e7006d2243231e9"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Personal PC\\Videos\\an2 sem1\\probabilitati si statistica\\pythonProject\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets evaluate --quiet\n",
    "\n",
    "from transformers import pipeline, set_seed, AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import random\n",
    "import evaluate\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-13T11:08:11.908727800Z",
     "start_time": "2025-05-13T11:07:59.227794100Z"
    }
   },
   "id": "af4a3a167861f3ce"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "set_seed(42)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-13T11:08:13.379827Z",
     "start_time": "2025-05-13T11:08:13.368857900Z"
    }
   },
   "id": "66480f8fb5e3f0da"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"The sun sets behind the hill,\",\n",
    "    \"Through forest deep and shadowed glen,\",\n",
    "    \"Upon the sea's eternal crest,\",\n",
    "    \"Soft winds blow through fields of rye,\"\n",
    "]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-13T11:08:18.736295Z",
     "start_time": "2025-05-13T11:08:18.727228100Z"
    }
   },
   "id": "26fa9dc4f2f5366d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## a. Generare cu LLM pre-antrenat (generalist)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b66488e92c9a9cc5"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: The sun sets behind the hill,\n",
      "The sun sets behind the hill, but it’s not the only color change. The grass is still green, but the leaves are brown,\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Through forest deep and shadowed glen,\n",
      "Through forest deep and shadowed glen,\n",
      "\n",
      "The great, wild, untamed,\n",
      "\n",
      "The Great, Wild, Untamed\n",
      "\n",
      "\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Upon the sea's eternal crest,\n",
      "Upon the sea's eternal crest, when the wind blows cold,\n",
      "\n",
      "And the waves beat in the light of the moon,\n",
      "\n",
      "O'\n",
      "----------------------------------------\n",
      "Prompt: Soft winds blow through fields of rye,\n",
      "Soft winds blow through fields of rye, oats, and the like, and the\n",
      "greater the distance from the village, the more distinctly the sky\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "generator_general = pipeline(\"text-generation\", model=\"EleutherAI/gpt-neo-1.3B\", device=0 if device == \"cuda\" else -1)\n",
    "results_general = []\n",
    "\n",
    "for prompt in prompts:\n",
    "    generated = generator_general(prompt, max_length=30, num_return_sequences=1, temperature=0.7)[0]['generated_text']\n",
    "    results_general.append(generated)\n",
    "    print(f\"Prompt: {prompt}\\n{generated}\\n{'-'*40}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-13T11:08:57.733972700Z",
     "start_time": "2025-05-13T11:08:22.975275400Z"
    }
   },
   "id": "c15cafa2dc948613"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## b. Generare cu LLM adaptat pe corpus de poezii"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b53603cc83f3ab87"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal PC\\Videos\\an2 sem1\\probabilitati si statistica\\pythonProject\\venv\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: The sun sets behind the hill,\n",
      "The sun sets behind the hill, and the sky is a deep blue. The wind is blowing, and the trees are swaying in the wind. The grass is green, and the grass is green\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Through forest deep and shadowed glen,\n",
      "Through forest deep and shadowed glen, the\n",
      "\n",
      "darkness of the night\n",
      "\n",
      "is the only light\n",
      "\n",
      "that I see\n",
      "\n",
      "and I am\n",
      "\n",
      "the only one\n",
      "\n",
      "\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Upon the sea's eternal crest,\n",
      "Upon the sea's eternal crest,\n",
      "\n",
      "The sea's eternal crest,\n",
      "\n",
      "The sea's eternal crest,\n",
      "\n",
      "The sea's eternal crest,\n",
      "\n",
      "The sea's eternal crest,\n",
      "\n",
      "----------------------------------------\n",
      "Prompt: Soft winds blow through fields of rye,\n",
      "Soft winds blow through fields of rye, and the air is filled with the smell of burning hay. The sun is hot, and the air is heavy with the scent of burning wood. The wind is\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_name = \"EleutherAI/gpt-neo-1.3B\"  # Model open-source, performant\n",
    "\n",
    "tokenizer_poetry = AutoTokenizer.from_pretrained(model_name)\n",
    "model_poetry = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "\n",
    "def generate_poetry(prompt):\n",
    "    inputs = tokenizer_poetry(prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = model_poetry.generate(**inputs, max_length=40, temperature=0.8)\n",
    "    return tokenizer_poetry.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "results_poetry = []\n",
    "for prompt in prompts:\n",
    "    poem = generate_poetry(prompt)\n",
    "    results_poetry.append(poem)\n",
    "    print(f\"Prompt: {prompt}\\n{poem}\\n{'-'*40}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-13T11:09:54.756701800Z",
     "start_time": "2025-05-13T11:09:09.025376900Z"
    }
   },
   "id": "13aa8192bd644394"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## c. Analiză calitativă și lingvistică"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "269627904bd17e98"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scor BLEU - LLM generalist: {'bleu': 0.23386215282576533, 'precisions': [0.29292929292929293, 0.25263157894736843, 0.21978021978021978, 0.1839080459770115], 'brevity_penalty': 1.0, 'length_ratio': 2.475, 'translation_length': 99, 'reference_length': 40}\n",
      "Scor BLEU - LLM poetic: {'bleu': 0.1796755015116255, 'precisions': [0.24615384615384617, 0.19047619047619047, 0.16393442622950818, 0.13559322033898305], 'brevity_penalty': 1.0, 'length_ratio': 3.25, 'translation_length': 130, 'reference_length': 40}\n"
     ]
    }
   ],
   "source": [
    "bleu = evaluate.load(\"bleu\")\n",
    "\n",
    "# Exemplu simplificat de comparație BLEU între general și poetic\n",
    "references = [[p + \" ...\"] for p in prompts]  # referințe simple\n",
    "candidates = results_general[:len(prompts)]\n",
    "score_general = bleu.compute(predictions=candidates, references=references)\n",
    "\n",
    "candidates_poetic = results_poetry[:len(prompts)]\n",
    "score_poetry = bleu.compute(predictions=candidates_poetic, references=references)\n",
    "\n",
    "print(\"Scor BLEU - LLM generalist:\", score_general)\n",
    "print(\"Scor BLEU - LLM poetic:\", score_poetry)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-13T11:10:00.471044100Z",
     "start_time": "2025-05-13T11:09:58.656512Z"
    }
   },
   "id": "3521c93c68c8df42"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Întrebări:\n",
    "- **c.1** Textele generate cu LLM poetic sunt mai coerente stilistic, dar mai puțin diverse.\n",
    "- **c.2** Prompturile în engleză funcționează bine cu modele antrenate în engleză.\n",
    "- **c.3** Prompturile în română nu oferă rezultate bune fără modele în română.\n",
    "- **c.4** Prompt în română + model în engleză => incoerență majoră.\n",
    "- **c.5** Pentru pasteluri, fine-tuning pe un corpus tematic sau prompt engineering cu instrucțiuni explicite (ex: \"Write in the style of a Romanian pastel poet\").\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8ff22ae82ccc8f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Salvarea poeziei preferate"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a089f7e0ea8700f"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poezia a fost salvată.\n"
     ]
    }
   ],
   "source": [
    "poezie_preferata = results_poetry[0]\n",
    "with open(\"poezie_preferata.txt\", \"w\") as f:\n",
    "    f.write(poezie_preferata)\n",
    "print(\"Poezia a fost salvată.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-13T11:10:08.707853400Z",
     "start_time": "2025-05-13T11:10:08.683391Z"
    }
   },
   "id": "8a5a37c97c49bd9e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
